{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignmnet 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('amesHousePrice.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                  0\n",
       "MSSubClass          0\n",
       "MSZoning            0\n",
       "LotFrontage       259\n",
       "LotArea             0\n",
       "Street              0\n",
       "Alley            1369\n",
       "LotShape            0\n",
       "LandContour         0\n",
       "Utilities           0\n",
       "LotConfig           0\n",
       "LandSlope           0\n",
       "Neighborhood        0\n",
       "Condition1          0\n",
       "Condition2          0\n",
       "BldgType            0\n",
       "HouseStyle          0\n",
       "OverallQual         0\n",
       "OverallCond         0\n",
       "YearBuilt           0\n",
       "YearRemodAdd        0\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "Exterior1st         0\n",
       "Exterior2nd         0\n",
       "MasVnrType          8\n",
       "MasVnrArea          8\n",
       "ExterQual           0\n",
       "ExterCond           0\n",
       "Foundation          0\n",
       "                 ... \n",
       "BedroomAbvGr        0\n",
       "KitchenAbvGr        0\n",
       "KitchenQual         0\n",
       "TotRmsAbvGrd        0\n",
       "Functional          0\n",
       "Fireplaces          0\n",
       "FireplaceQu       690\n",
       "GarageType         81\n",
       "GarageYrBlt        81\n",
       "GarageFinish       81\n",
       "GarageCars          0\n",
       "GarageArea          0\n",
       "GarageQual         81\n",
       "GarageCond         81\n",
       "PavedDrive          0\n",
       "WoodDeckSF          0\n",
       "OpenPorchSF         0\n",
       "EnclosedPorch       0\n",
       "3SsnPorch           0\n",
       "ScreenPorch         0\n",
       "PoolArea            0\n",
       "PoolQC           1453\n",
       "Fence            1179\n",
       "MiscFeature      1406\n",
       "MiscVal             0\n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            0\n",
       "SaleCondition       0\n",
       "SalePrice           0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, ..., 2.10000e+01,\n",
       "        3.96900e+02, 1.87200e+01],\n",
       "       [2.17700e-02, 8.25000e+01, 2.03000e+00, ..., 1.47000e+01,\n",
       "        3.95380e+02, 3.11000e+00],\n",
       "       [4.89822e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "        3.75520e+02, 3.26000e+00],\n",
       "       ...,\n",
       "       [3.46600e-02, 3.50000e+01, 6.06000e+00, ..., 1.69000e+01,\n",
       "        3.62250e+02, 7.83000e+00],\n",
       "       [2.14918e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        2.61950e+02, 1.57900e+01],\n",
       "       [1.43900e-02, 6.00000e+01, 2.93000e+00, ..., 1.56000e+01,\n",
       "        3.76700e+02, 4.38000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(1, input_dim=13, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "404/404 [==============================] - 0s 751us/sample - loss: -547.6660 - acc: 0.0000e+00\n",
      "Epoch 2/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -794.7640 - acc: 0.0000e+00\n",
      "Epoch 3/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -1042.4536 - acc: 0.0000e+00\n",
      "Epoch 4/150\n",
      "404/404 [==============================] - 0s 50us/sample - loss: -1291.7123 - acc: 0.0000e+00\n",
      "Epoch 5/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -1537.7425 - acc: 0.0000e+00\n",
      "Epoch 6/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -1785.3073 - acc: 0.0000e+00\n",
      "Epoch 7/150\n",
      "404/404 [==============================] - 0s 50us/sample - loss: -2034.2682 - acc: 0.0000e+00\n",
      "Epoch 8/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -2281.2656 - acc: 0.0000e+00\n",
      "Epoch 9/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -2527.4409 - acc: 0.0000e+00\n",
      "Epoch 10/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -2770.8501 - acc: 0.0000e+00\n",
      "Epoch 11/150\n",
      "404/404 [==============================] - 0s 53us/sample - loss: -3016.4315 - acc: 0.0000e+00\n",
      "Epoch 12/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -3260.0725 - acc: 0.0000e+00\n",
      "Epoch 13/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -3503.7768 - acc: 0.0000e+00\n",
      "Epoch 14/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -3745.3012 - acc: 0.0000e+00\n",
      "Epoch 15/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -3989.8372 - acc: 0.0000e+00\n",
      "Epoch 16/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -4233.2986 - acc: 0.0000e+00\n",
      "Epoch 17/150\n",
      "404/404 [==============================] - 0s 57us/sample - loss: -4478.8326 - acc: 0.0000e+00\n",
      "Epoch 18/150\n",
      "404/404 [==============================] - 0s 45us/sample - loss: -4722.0685 - acc: 0.0000e+00\n",
      "Epoch 19/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -4963.7259 - acc: 0.0000e+00\n",
      "Epoch 20/150\n",
      "404/404 [==============================] - 0s 52us/sample - loss: -5209.2996 - acc: 0.0000e+00\n",
      "Epoch 21/150\n",
      "404/404 [==============================] - 0s 49us/sample - loss: -5453.1981 - acc: 0.0000e+00\n",
      "Epoch 22/150\n",
      "404/404 [==============================] - 0s 55us/sample - loss: -5696.2388 - acc: 0.0000e+00\n",
      "Epoch 23/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -5937.6977 - acc: 0.0000e+00\n",
      "Epoch 24/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -6181.9862 - acc: 0.0000e+00\n",
      "Epoch 25/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -6426.9658 - acc: 0.0000e+00\n",
      "Epoch 26/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -6670.5146 - acc: 0.0000e+00\n",
      "Epoch 27/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -6911.4376 - acc: 0.0000e+00\n",
      "Epoch 28/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -7157.4660 - acc: 0.0000e+00\n",
      "Epoch 29/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -7399.1000 - acc: 0.0000e+00\n",
      "Epoch 30/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -7642.8568 - acc: 0.0000e+00\n",
      "Epoch 31/150\n",
      "404/404 [==============================] - 0s 54us/sample - loss: -7884.1345 - acc: 0.0000e+00\n",
      "Epoch 32/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -8127.7706 - acc: 0.0000e+00\n",
      "Epoch 33/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -8371.4585 - acc: 0.0000e+00\n",
      "Epoch 34/150\n",
      "404/404 [==============================] - 0s 49us/sample - loss: -8612.3430 - acc: 0.0000e+00\n",
      "Epoch 35/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -8856.0955 - acc: 0.0000e+00\n",
      "Epoch 36/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -9099.2503 - acc: 0.0000e+00\n",
      "Epoch 37/150\n",
      "404/404 [==============================] - 0s 49us/sample - loss: -9342.8910 - acc: 0.0000e+00\n",
      "Epoch 38/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -9585.4981 - acc: 0.0000e+00\n",
      "Epoch 39/150\n",
      "404/404 [==============================] - 0s 57us/sample - loss: -9829.2363 - acc: 0.0000e+00\n",
      "Epoch 40/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -10073.1222 - acc: 0.0000e+00\n",
      "Epoch 41/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -10315.7100 - acc: 0.0000e+00\n",
      "Epoch 42/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -10556.8867 - acc: 0.0000e+00\n",
      "Epoch 43/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -10801.2473 - acc: 0.0000e+00\n",
      "Epoch 44/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -11044.3206 - acc: 0.0000e+00\n",
      "Epoch 45/150\n",
      "404/404 [==============================] - 0s 51us/sample - loss: -11287.4485 - acc: 0.0000e+00\n",
      "Epoch 46/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -11528.4478 - acc: 0.0000e+00\n",
      "Epoch 47/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -11771.6546 - acc: 0.0000e+00\n",
      "Epoch 48/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -12015.9577 - acc: 0.0000e+00\n",
      "Epoch 49/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -12260.2962 - acc: 0.0000e+00\n",
      "Epoch 50/150\n",
      "404/404 [==============================] - 0s 56us/sample - loss: -12502.1092 - acc: 0.0000e+00\n",
      "Epoch 51/150\n",
      "404/404 [==============================] - 0s 45us/sample - loss: -12746.9251 - acc: 0.0000e+00\n",
      "Epoch 52/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -12991.2168 - acc: 0.0000e+00\n",
      "Epoch 53/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -13234.4525 - acc: 0.0000e+00\n",
      "Epoch 54/150\n",
      "404/404 [==============================] - 0s 49us/sample - loss: -13475.4688 - acc: 0.0000e+00\n",
      "Epoch 55/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -13721.0057 - acc: 0.0000e+00\n",
      "Epoch 56/150\n",
      "404/404 [==============================] - 0s 45us/sample - loss: -13967.1713 - acc: 0.0000e+00\n",
      "Epoch 57/150\n",
      "404/404 [==============================] - 0s 44us/sample - loss: -14210.2387 - acc: 0.0000e+00\n",
      "Epoch 58/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -14453.1990 - acc: 0.0000e+00\n",
      "Epoch 59/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -14699.1408 - acc: 0.0000e+00\n",
      "Epoch 60/150\n",
      "404/404 [==============================] - 0s 43us/sample - loss: -14942.5152 - acc: 0.0000e+00\n",
      "Epoch 61/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -15183.6879 - acc: 0.0000e+00\n",
      "Epoch 62/150\n",
      "404/404 [==============================] - 0s 54us/sample - loss: -15431.2557 - acc: 0.0000e+00\n",
      "Epoch 63/150\n",
      "404/404 [==============================] - 0s 49us/sample - loss: -15673.2063 - acc: 0.0000e+00\n",
      "Epoch 64/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -15915.3524 - acc: 0.0000e+00\n",
      "Epoch 65/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -16160.6150 - acc: 0.0000e+00\n",
      "Epoch 66/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -16402.8301 - acc: 0.0000e+00\n",
      "Epoch 67/150\n",
      "404/404 [==============================] - 0s 44us/sample - loss: -16646.5926 - acc: 0.0000e+00\n",
      "Epoch 68/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -16889.2218 - acc: 0.0000e+00\n",
      "Epoch 69/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -17132.3085 - acc: 0.0000e+00\n",
      "Epoch 70/150\n",
      "404/404 [==============================] - 0s 53us/sample - loss: -17376.4575 - acc: 0.0000e+00\n",
      "Epoch 71/150\n",
      "404/404 [==============================] - 0s 52us/sample - loss: -17619.4459 - acc: 0.0000e+00\n",
      "Epoch 72/150\n",
      "404/404 [==============================] - 0s 49us/sample - loss: -17865.3140 - acc: 0.0000e+00\n",
      "Epoch 73/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -18106.4553 - acc: 0.0000e+00\n",
      "Epoch 74/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -18349.6895 - acc: 0.0000e+00\n",
      "Epoch 75/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -18593.4642 - acc: 0.0000e+00\n",
      "Epoch 76/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -18838.2195 - acc: 0.0000e+00\n",
      "Epoch 77/150\n",
      "404/404 [==============================] - 0s 51us/sample - loss: -19081.3912 - acc: 0.0000e+00\n",
      "Epoch 78/150\n",
      "404/404 [==============================] - 0s 50us/sample - loss: -19326.6026 - acc: 0.0000e+00\n",
      "Epoch 79/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -19570.0270 - acc: 0.0000e+00\n",
      "Epoch 80/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -19816.8401 - acc: 0.0000e+00\n",
      "Epoch 81/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -20056.0806 - acc: 0.0000e+00\n",
      "Epoch 82/150\n",
      "404/404 [==============================] - 0s 49us/sample - loss: -20303.2553 - acc: 0.0000e+00\n",
      "Epoch 83/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -20546.3653 - acc: 0.0000e+00\n",
      "Epoch 84/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -20790.7678 - acc: 0.0000e+00\n",
      "Epoch 85/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -21034.3972 - acc: 0.0000e+00\n",
      "Epoch 86/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -21278.8936 - acc: 0.0000e+00\n",
      "Epoch 87/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -21522.9299 - acc: 0.0000e+00\n",
      "Epoch 88/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -21767.6080 - acc: 0.0000e+00\n",
      "Epoch 89/150\n",
      "404/404 [==============================] - 0s 50us/sample - loss: -22010.2742 - acc: 0.0000e+00\n",
      "Epoch 90/150\n",
      "404/404 [==============================] - 0s 45us/sample - loss: -22255.2039 - acc: 0.0000e+00\n",
      "Epoch 91/150\n",
      "404/404 [==============================] - 0s 44us/sample - loss: -22496.6578 - acc: 0.0000e+00\n",
      "Epoch 92/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -22742.3346 - acc: 0.0000e+00\n",
      "Epoch 93/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -22985.7071 - acc: 0.0000e+00\n",
      "Epoch 94/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -23231.1934 - acc: 0.0000e+00\n",
      "Epoch 95/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -23473.0458 - acc: 0.0000e+00\n",
      "Epoch 96/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -23718.7743 - acc: 0.0000e+00\n",
      "Epoch 97/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -23962.8435 - acc: 0.0000e+00\n",
      "Epoch 98/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -24205.6866 - acc: 0.0000e+00\n",
      "Epoch 99/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -24451.2947 - acc: 0.0000e+00\n",
      "Epoch 100/150\n",
      "404/404 [==============================] - 0s 51us/sample - loss: -24693.6277 - acc: 0.0000e+00\n",
      "Epoch 101/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -24937.2591 - acc: 0.0000e+00\n",
      "Epoch 102/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -25181.6681 - acc: 0.0000e+00\n",
      "Epoch 103/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -25426.8140 - acc: 0.0000e+00\n",
      "Epoch 104/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -25670.1459 - acc: 0.0000e+00\n",
      "Epoch 105/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -25912.4458 - acc: 0.0000e+00\n",
      "Epoch 106/150\n",
      "404/404 [==============================] - 0s 45us/sample - loss: -26157.0260 - acc: 0.0000e+00\n",
      "Epoch 107/150\n",
      "404/404 [==============================] - 0s 49us/sample - loss: -26400.3510 - acc: 0.0000e+00\n",
      "Epoch 108/150\n",
      "404/404 [==============================] - 0s 44us/sample - loss: -26645.5399 - acc: 0.0000e+00\n",
      "Epoch 109/150\n",
      "404/404 [==============================] - 0s 45us/sample - loss: -26888.4268 - acc: 0.0000e+00\n",
      "Epoch 110/150\n",
      "404/404 [==============================] - 0s 50us/sample - loss: -27132.0015 - acc: 0.0000e+00\n",
      "Epoch 111/150\n",
      "404/404 [==============================] - 0s 45us/sample - loss: -27375.7021 - acc: 0.0000e+00\n",
      "Epoch 112/150\n",
      "404/404 [==============================] - 0s 45us/sample - loss: -27621.2525 - acc: 0.0000e+00\n",
      "Epoch 113/150\n",
      "404/404 [==============================] - 0s 50us/sample - loss: -27863.9977 - acc: 0.0000e+00\n",
      "Epoch 114/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -28106.3959 - acc: 0.0000e+00\n",
      "Epoch 115/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -28352.0356 - acc: 0.0000e+00\n",
      "Epoch 116/150\n",
      "404/404 [==============================] - 0s 50us/sample - loss: -28595.1346 - acc: 0.0000e+00\n",
      "Epoch 117/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -28836.3538 - acc: 0.0000e+00\n",
      "Epoch 118/150\n",
      "404/404 [==============================] - 0s 50us/sample - loss: -29085.8229 - acc: 0.0000e+00\n",
      "Epoch 119/150\n",
      "404/404 [==============================] - 0s 54us/sample - loss: -29325.2957 - acc: 0.0000e+00\n",
      "Epoch 120/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -29572.3730 - acc: 0.0000e+00\n",
      "Epoch 121/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -29815.7110 - acc: 0.0000e+00\n",
      "Epoch 122/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -30059.8569 - acc: 0.0000e+00\n",
      "Epoch 123/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -30303.9991 - acc: 0.0000e+00\n",
      "Epoch 124/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -30547.0509 - acc: 0.0000e+00\n",
      "Epoch 125/150\n",
      "404/404 [==============================] - 0s 44us/sample - loss: -30793.3279 - acc: 0.0000e+00\n",
      "Epoch 126/150\n",
      "404/404 [==============================] - 0s 45us/sample - loss: -31035.8666 - acc: 0.0000e+00\n",
      "Epoch 127/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -31282.1564 - acc: 0.0000e+00\n",
      "Epoch 128/150\n",
      "404/404 [==============================] - 0s 45us/sample - loss: -31524.1842 - acc: 0.0000e+00\n",
      "Epoch 129/150\n",
      "404/404 [==============================] - 0s 51us/sample - loss: -31769.2113 - acc: 0.0000e+00\n",
      "Epoch 130/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -32013.5458 - acc: 0.0000e+00\n",
      "Epoch 131/150\n",
      "404/404 [==============================] - 0s 49us/sample - loss: -32256.5970 - acc: 0.0000e+00\n",
      "Epoch 132/150\n",
      "404/404 [==============================] - 0s 58us/sample - loss: -32502.2513 - acc: 0.0000e+00\n",
      "Epoch 133/150\n",
      "404/404 [==============================] - 0s 45us/sample - loss: -32743.2099 - acc: 0.0000e+00\n",
      "Epoch 134/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -32987.3692 - acc: 0.0000e+00\n",
      "Epoch 135/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -33232.0338 - acc: 0.0000e+00\n",
      "Epoch 136/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -33475.7907 - acc: 0.0000e+00\n",
      "Epoch 137/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -33720.8689 - acc: 0.0000e+00\n",
      "Epoch 138/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -33963.5199 - acc: 0.0000e+00\n",
      "Epoch 139/150\n",
      "404/404 [==============================] - 0s 47us/sample - loss: -34208.3687 - acc: 0.0000e+00\n",
      "Epoch 140/150\n",
      "404/404 [==============================] - 0s 51us/sample - loss: -34452.9756 - acc: 0.0000e+00\n",
      "Epoch 141/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -34697.7316 - acc: 0.0000e+00\n",
      "Epoch 142/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -34940.5074 - acc: 0.0000e+00\n",
      "Epoch 143/150\n",
      "404/404 [==============================] - 0s 49us/sample - loss: -35187.6471 - acc: 0.0000e+00\n",
      "Epoch 144/150\n",
      "404/404 [==============================] - 0s 45us/sample - loss: -35428.0169 - acc: 0.0000e+00\n",
      "Epoch 145/150\n",
      "404/404 [==============================] - 0s 50us/sample - loss: -35676.5493 - acc: 0.0000e+00\n",
      "Epoch 146/150\n",
      "404/404 [==============================] - 0s 45us/sample - loss: -35920.4758 - acc: 0.0000e+00\n",
      "Epoch 147/150\n",
      "404/404 [==============================] - 0s 45us/sample - loss: -36164.0945 - acc: 0.0000e+00\n",
      "Epoch 148/150\n",
      "404/404 [==============================] - 0s 48us/sample - loss: -36409.1075 - acc: 0.0000e+00\n",
      "Epoch 149/150\n",
      "404/404 [==============================] - 0s 52us/sample - loss: -36651.3096 - acc: 0.0000e+00\n",
      "Epoch 150/150\n",
      "404/404 [==============================] - 0s 46us/sample - loss: -36894.8132 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9734f08908>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 3us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 4s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_rows * img_cols)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows * img_cols)\n",
    "\n",
    "# Normalize Our Data\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model 2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense1 (Dense)               (None, 4)                 3140      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 3,159\n",
      "Trainable params: 3,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential(name=\"Model 2\")\n",
    "\n",
    "model2.add(Dense(4, input_dim=784, activation='relu', name=\"Dense1\"))\n",
    "model2.add(Dense(3, activation='sigmoid'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Let's inspect our new architecture\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f971664eb70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=150, verbose=False) # What parameters can I specify here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 31us/sample - loss: -3934.5862 - acc: 0.1000\n",
      "acc: 10.000000149011612\n"
     ]
    }
   ],
   "source": [
    "scores = model2.evaluate(x_train,y_train)\n",
    "print(f\"{model2.metrics_names[1]}: {scores[1]*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
